import torch
import torch.nn.functional as F

class CustomFeedforwardNet:
    def __init__(self, input_size=3, hidden_layers=4, hidden_size=3, lr=0.001):
        self.lr = lr

        # Create weights and biases for each layer
        self.weights = [
            torch.full((hidden_size, input_size), 1.0, requires_grad=True)
            for _ in range(hidden_layers)
        ]
        self.biases = [
            torch.full((hidden_size,), 1.0, requires_grad=True)
            for _ in range(hidden_layers)
        ]

    def forward(self, x):
        for w, b in zip(self.weights, self.biases):
            z = torch.sign(x) * (torch.abs(x) ** w)     # Custom nonlinearity
            a = z.sum(dim=1) + b                         # Activation vector
            x = a.unsqueeze(1).expand(-1, x.shape[1])    # Expand for next layer
        return a.sum().reshape(1, 1)                     # Final scalar output

    def parameters(self):
        return self.weights + self.biases

    def train(self, x, y_true, epochs=3000):
        for epoch in range(epochs):
            y_pred = self.forward(x)
            loss = F.mse_loss(y_pred, y_true)

            loss.backward()

            with torch.no_grad():
                for param in self.parameters():
                    param -= self.lr * param.grad
                    param.grad.zero_()

            if epoch % 50 == 0:
                print(f"Epoch {epoch}, Loss: {loss.item():.6f}")

        print("\nFinal prediction:", y_pred.detach().numpy())


def main():
    # Demo input and target
    input = torch.tensor([[1.0, 2.0, 3.0]]).repeat(3, 1)  # Shape: (3, 3)
    target = torch.tensor([[1.0]])                       # Shape: (1, 1)

    # Initialize and train model
    model = CustomFeedforwardNet()
    model.train(input, target)

if __name__ == "__main__":
    main()
